{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "import os \n",
    "import feather\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import MLE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from models import ngb\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "WU = feather.read_dataframe('Data/WU_lag.feather')\n",
    "\n",
    "#pp\n",
    "WU = WU.drop(columns=['Index','year','ParcelID','Days','year','month'])\n",
    "\n",
    "\n",
    "WU_train = WU[WU['Set'] == 'train'].drop(columns=['Set'])\n",
    "WU_dev = WU[WU['Set'] == 'dev'].drop(columns=['Set'])\n",
    "WU_test = WU[WU['Set'] == 'test'].drop(columns=['Set'])\n",
    "\n",
    "WU_train_all =  WU[WU['Set'] != 'test'].drop(columns=['Set'])\n",
    "\n",
    "predictors = list( WU_train.drop(columns=['TotalWaterUse']).columns)\n",
    "\n",
    "X_train = WU_train.drop(columns=['TotalWaterUse']).values\n",
    "Y_train = WU_train.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_dev = WU_dev.drop(columns=['TotalWaterUse']).values\n",
    "Y_dev = WU_dev.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_test = WU_test.drop(columns=['TotalWaterUse']).values\n",
    "Y_test = WU_test.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_train_all = WU_train_all.drop(columns=['TotalWaterUse']).values\n",
    "Y_train_all = WU_train_all.loc[:,'TotalWaterUse'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_par = ngb.ngbBayesVal(X_train, Y_train, X_dev, Y_dev, eta = eta, max_eval=20) # tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par = {'max_depth': 26.0, 'min_samples_split': 870.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tree_learner2 = DecisionTreeRegressor(criterion='friedman_mse',\n",
    "                                              min_samples_split = int(best_par['min_samples_split']),\n",
    "                                              max_depth= int(best_par['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor( learning_rate=eta , n_estimators= 400 , Dist=Normal, Score=MLE,\n",
    "                       Base = default_tree_learner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=9.4240 val_loss=9.4873 scale=1.0000 norm=2342.8823\n",
      "[iter 100] loss=9.1054 val_loss=9.1647 scale=1.0000 norm=1779.9097\n",
      "[iter 200] loss=8.9485 val_loss=9.0655 scale=1.0000 norm=1593.8943\n",
      "[iter 300] loss=8.8644 val_loss=9.0375 scale=1.0000 norm=1512.1123\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL321 (val_loss=9.0357)\n"
     ]
    }
   ],
   "source": [
    "ngb = ngb_reg.fit(X = X_train, Y = Y_train, X_val = X_dev, Y_val = Y_dev, early_stopping_rounds=10)\n",
    "Y_preds = ngb.predict(X_dev)   \n",
    "Y_dists = ngb.pred_dist(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n"
     ]
    }
   ],
   "source": [
    "ntree = ngb.best_val_loss_itr\n",
    "print(ntree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = ngb.pred_param(X_dev)\n",
    "pars[:,1] = np.exp(pars[:,1])\n",
    "y_hat = pars[:,0]\n",
    "sig_hat = pars[:,1]\n",
    "\n",
    "WU2 = feather.read_dataframe('Data/WU.feather')\n",
    "WU2[WU2.loc[:,'Set']=='dev'].loc[:,'Index'].values\n",
    "all_test_MF = pd.DataFrame({\n",
    "    'Index': WU2[WU2.loc[:,'Set']=='dev'].loc[:,'Index'].values,\n",
    "    'Y': Y_dev,\n",
    "    'y_hat': y_hat,\n",
    "    'sig_hat': sig_hat,\n",
    "    'p_y': norm.pdf(Y_dev,loc=y_hat,scale=sig_hat)\n",
    "})\n",
    "\n",
    "path = 'Out_dev_MF\\\\month1\\\\NGB_dev_1m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor( learning_rate=eta , n_estimators= ntree , Dist=Normal, Score=MLE,\n",
    "                       Base = default_tree_learner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=9.4306 val_loss=0.0000 scale=1.0000 norm=2351.7255\n",
      "[iter 100] loss=9.0950 val_loss=0.0000 scale=1.0000 norm=1762.4663\n",
      "[iter 200] loss=8.9312 val_loss=0.0000 scale=2.0000 norm=3149.5306\n",
      "[iter 300] loss=8.8476 val_loss=0.0000 scale=1.0000 norm=1500.7142\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ngb_test = ngb_reg.fit(X = X_train_all, Y = Y_train_all)\n",
    "Y_preds = ngb_test.predict(X_test)   \n",
    "Y_dists = ngb_test.pred_dist(X_test)\n",
    "sig_hat = pars[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & 2451.74 & 9.06 & 10911.62 & 8082.53 & 0.92 & 95\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "pars = ngb_test.pred_param(X_test)\n",
    "zp95 = 1.959963984540\n",
    "y_hat = pars[:,0]\n",
    "sig_hat = np.exp(pars[:,1])\n",
    "left2 = (y_hat - sig_hat*zp95)\n",
    "right = (y_hat + sig_hat*zp95)\n",
    "\n",
    "\n",
    "r1,r2,r3,r4,r5 = get_RMSE_NLL_NOIS_AWPI_ECPI(Y_test,y_hat,left2,right,alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "with open(\"Results/Short_term_results.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"NGBoost \\n\")\n",
    "    myfile.write('RMSE %f & NLL %f & NOIS %f & AWPI %f & ECPI %f \\n' % (\n",
    "        r1,r2,r3,r4,r5 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "WU2 = feather.read_dataframe('Data/WU.feather')\n",
    "WU2[WU2.loc[:,'Set']=='test'].loc[:,'Index'].values\n",
    "all_test_MF = pd.DataFrame({\n",
    "    'Index': WU2[WU2.loc[:,'Set']=='test'].loc[:,'Index'].values,\n",
    "    'Y': Y_test,\n",
    "    'y_hat': y_hat,\n",
    "    'sig_hat': sig_hat,\n",
    "    'p_y': norm.pdf(Y_test,loc=y_hat,scale=sig_hat)\n",
    "})\n",
    "\n",
    "path =  'Out_test_MF\\\\month1\\\\NGB_1m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMA liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = ngb_test.pred_param(X_train_all)\n",
    "preds = pars[:,1]\n",
    "miu = pars[:,0]\n",
    "y =Y_train_all\n",
    "pi =  np.full(fill_value= np.pi, shape=np.shape(y)[0],dtype=float)\n",
    "nll = ( np.sum(0.5 *np.log(2*pi) + preds + 0.5 * ((y - miu)**2) * np.exp(-2*preds)))/y.shape[0]\n",
    "\n",
    "with open(\"Ensemble/BMA_short.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"NGBoost, %f \\n\" % (nll))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
