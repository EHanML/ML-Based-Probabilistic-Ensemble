{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "import os \n",
    "import feather\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from models import rf\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "WU = feather.read_dataframe('Data/WU.feather')\n",
    "WU2 = WU\n",
    "#pp\n",
    "WU = WU.drop(columns=['Index','year','ParcelID','Days','year','month'])\n",
    "\n",
    "\n",
    "WU_train = WU[WU['Set'] == 'train'].drop(columns=['Set'])\n",
    "WU_dev = WU[WU['Set'] == 'dev'].drop(columns=['Set'])\n",
    "WU_test = WU[WU['Set'] == 'test'].drop(columns=['Set'])\n",
    "\n",
    "WU_train_all =  WU[WU['Set'] != 'test'].drop(columns=['Set'])\n",
    "\n",
    "predictors = list( WU_train.drop(columns=['TotalWaterUse']).columns)\n",
    "\n",
    "X_train = WU_train.drop(columns=['TotalWaterUse']).values\n",
    "Y_train = WU_train.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_dev = WU_dev.drop(columns=['TotalWaterUse']).values\n",
    "Y_dev = WU_dev.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_test = WU_test.drop(columns=['TotalWaterUse']).values\n",
    "Y_test = WU_test.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_train_all = WU_train_all.drop(columns=['TotalWaterUse']).values\n",
    "Y_train_all = WU_train_all.loc[:,'TotalWaterUse'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UQRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg, tau, mtry, nll = rf.gridRF(X_train, Y_train, X_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev\n",
    "tau, mtry = 1.86920166015625e-06, 5\n",
    "\n",
    "model = rf.rf(X_train, Y_train, mtry = mtry, tau = tau) \n",
    "\n",
    "y_hat, L_hat, U_hat, p_y, sig_hat, _ = model.predict_MC(X_dev, Y_dev, alpha= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_dev\n",
    "all_test_MF = pd.DataFrame({\n",
    "    'Index': WU2[WU2.loc[:,'Set']=='dev'].loc[:,'Index'].values,\n",
    "    'Y': y_true,\n",
    "    'y_hat': y_hat,\n",
    "    'L': np.maximum(L_hat,0 ),\n",
    "    'U': U_hat,\n",
    "    'sig_hat': sig_hat,\n",
    "    'p_y':p_y\n",
    "})\n",
    "\n",
    "path = 'Out_dev_MF\\\\month12\\\\RF_dev_12m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model = rf.rf(X_train_all, Y_train_all, mtry = mtry, tau = tau) \n",
    "\n",
    "y_hat, L_hat, U_hat, p_y, sig_hat, y_MC_mixture = model.predict_MC(X_test, Y_test, alpha= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_test\n",
    "all_test_MF = pd.DataFrame({\n",
    "    'Index': WU2[WU2.loc[:,'Set']=='test'].loc[:,'Index'].values,\n",
    "    'Y': y_true,\n",
    "    'y_hat': y_hat,\n",
    "    'L': np.maximum(L_hat,0 ),\n",
    "    'U': U_hat,\n",
    "    'sig_hat': sig_hat,\n",
    "    'p_y':p_y\n",
    "})\n",
    "\n",
    "path = 'Out_test_MF\\\\month12\\\\RF_12m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)\n",
    "\n",
    "path = 'Out_test_MF\\\\month12\\\\RF_MC.npy'\n",
    "np.save(path, y_MC_mixture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & 2562.25 & 9.19 & 13209.34 & 9258.59 & 0.93 & 95\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "r1,r2,r3,r4,r5 = get_RMSE_NLL_NOIS_AWPI_ECPI(Y_test,y_hat,np.maximum(L_hat,0 ), U_hat,alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "with open(\"Results/Results_12m.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"RF \\n\")\n",
    "    myfile.write('RMSE %f & NLL %f & NOIS %f & AWPI %f & ECPI %f \\n' % (\n",
    "        r1,-np.log(p_y).mean(),r3,r4,r5 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tau, rmse, nll, _ = model.predict(X_train_all, Y_train_all)\n",
    "with open(\"Ensemble/BMA_long.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"RF, %f \\n\" % (nll))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
