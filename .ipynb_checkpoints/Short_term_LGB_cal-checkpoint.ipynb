{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "import os \n",
    "import feather\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from models import lgbm\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "WU = feather.read_dataframe('Data/WU_lag.feather')\n",
    "\n",
    "#pp\n",
    "WU = WU.drop(columns=['Index','year','ParcelID','Days','year','month'])\n",
    "\n",
    "WU_train = WU[WU['Set'] == 'train'].drop(columns=['Set'])\n",
    "WU_dev = WU[WU['Set'] == 'dev'].drop(columns=['Set'])\n",
    "WU_test = WU[WU['Set'] == 'test'].drop(columns=['Set'])\n",
    "\n",
    "WU_train_all =  WU[WU['Set'] != 'test'].drop(columns=['Set'])\n",
    "\n",
    "predictors = list( WU_train.drop(columns=['TotalWaterUse']).columns)\n",
    "\n",
    "X_train = WU_train.drop(columns=['TotalWaterUse']).values\n",
    "Y_train = WU_train.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_dev = WU_dev.drop(columns=['TotalWaterUse']).values\n",
    "Y_dev = WU_dev.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_test = WU_test.drop(columns=['TotalWaterUse']).values\n",
    "Y_test = WU_test.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_train_all = WU_train_all.drop(columns=['TotalWaterUse']).values\n",
    "Y_train_all = WU_train_all.loc[:,'TotalWaterUse'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_par, ntree = lgbm.lgbBayesVal(X_train, Y_train, X_dev, Y_dev,predictors =predictors,  max_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par, ntree  = {'bagging_fraction': 0.9096129552174361,\n",
    "  'feature_fraction': 0.8958272129370544,\n",
    "  'max_depth': 10,\n",
    "  'min_data_in_leaf': 87.0,\n",
    "  'num_leaves': 5583.0}, 148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# dev\n",
    "lgb_model1_dev, ntree, score  = lgbm.LGB_run(X_train, Y_train, X_dev, Y_dev, params = best_par, predictors =predictors, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# test\n",
    "lgb_model1 , ntree, score  = lgbm.LGB_run(X_train_all, Y_train_all, X_test, Y_test, params = best_par, num_boost_round = ntree, early_stopping_rounds = ntree, predictors =predictors, verbose = False)\n",
    "\n",
    "lgb_y_hat = lgb_model1.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_par, ntree = lgbm.lgbBayesVal2(X_train, Y_train, X_dev, Y_dev, mu_model = lgb_model1_dev, predictors =predictors,  max_eval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par, ntree = {'bagging_fraction': 0.5287061838187463,\n",
    "  'feature_fraction': 0.5016077663494096,\n",
    "  'max_depth': 50,\n",
    "  'min_data_in_leaf': 1348.0,\n",
    "  'num_leaves': 11587.0}, 234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# dev\n",
    "lgb_model_dev, ntree, score  = lgbm.LGB_run2(X_train, Y_train, X_dev, Y_dev, mu_model = lgb_model1_dev, params = best_par, predictors =predictors, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_hat = np.exp(lgb_model_dev.predict(X_dev))\n",
    "y_hat = lgb_model1_dev.predict(X_dev)\n",
    "all_test_MF =  outframe('dev',Y_dev,y_hat,sig_hat)\n",
    "\n",
    "path = 'Out_dev_MF\\\\month1\\\\LGB_dev_1m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# test\n",
    "lgb_model2 , ntree, score  = lgbm.LGB_run2(X_train_all, Y_train_all, X_test, Y_test,mu_model = lgb_model1, params = best_par, num_boost_round = ntree, early_stopping_rounds = ntree, predictors =predictors, verbose = False)\n",
    "\n",
    "lgb_y_hat = lgb_model1.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zp90' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-790af2e7a12d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mzp95\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.959963984540\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mleft2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msig_hat\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzp90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msig_hat\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzp95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zp90' is not defined"
     ]
    }
   ],
   "source": [
    "sig_hat = np.exp(lgb_model2.predict(X_test))\n",
    "y_hat = lgb_model1.predict(X_test) \n",
    "zp95 = 1.959963984540\n",
    "left2 = (y_hat - sig_hat*zp90)\n",
    "right = (y_hat + sig_hat*zp95)\n",
    "\n",
    "r1,r2,r3,r4,r5 = get_RMSE_NLL_NOIS_AWPI_ECPI(Y_test,y_hat,left2,right,alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "with open(\"Results/Short_term_results.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"LGB \\n\")\n",
    "    myfile.write('RMSE %f & NLL %f & NOIS %f & AWPI %f & ECPI %f \\n' % (\n",
    "        r1,r2,r3,r4,r5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_test_MF = outframe('test',Y_test,y_hat,sig_hat)\n",
    "path = 'Out_test_MF\\\\month1\\\\LGB_1m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_tr = lgb_model1.predict(X_train_all)\n",
    "sig_hat_tr = np.exp(lgb_model2.predict(X_train_all, num_iteration=ntree))\n",
    "pt_y_tr = norm.pdf(Y_train_all,loc=y_hat_tr,scale=sig_hat_tr )\n",
    "nll = -np.mean(np.log(pt_y_tr))\n",
    "\n",
    "\n",
    "with open(\"Ensemble/BMA_short.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"LGB, %f \\n\" % (nll))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
