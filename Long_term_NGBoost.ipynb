{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import pandas as pd\n",
    "import os \n",
    "import feather\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner\n",
    "from ngboost.distns import Normal\n",
    "from ngboost.scores import MLE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from models import ngb\n",
    "from scipy.stats import norm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "WU = feather.read_dataframe('Data/WU.feather')\n",
    "\n",
    "#pp\n",
    "WU = WU.drop(columns=['Index','year','ParcelID','Days','year','month'])\n",
    "\n",
    "\n",
    "WU_train = WU[WU['Set'] == 'train'].drop(columns=['Set'])\n",
    "WU_dev = WU[WU['Set'] == 'dev'].drop(columns=['Set'])\n",
    "WU_test = WU[WU['Set'] == 'test'].drop(columns=['Set'])\n",
    "\n",
    "WU_train_all =  WU[WU['Set'] != 'test'].drop(columns=['Set'])\n",
    "\n",
    "predictors = list( WU_train.drop(columns=['TotalWaterUse']).columns)\n",
    "\n",
    "X_train = WU_train.drop(columns=['TotalWaterUse']).values\n",
    "Y_train = WU_train.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_dev = WU_dev.drop(columns=['TotalWaterUse']).values\n",
    "Y_dev = WU_dev.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_test = WU_test.drop(columns=['TotalWaterUse']).values\n",
    "Y_test = WU_test.loc[:,'TotalWaterUse'].values\n",
    "\n",
    "X_train_all = WU_train_all.drop(columns=['TotalWaterUse']).values\n",
    "Y_train_all = WU_train_all.loc[:,'TotalWaterUse'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_par = ngb.ngbBayesVal(X_train, Y_train, X_dev, Y_dev,eta = eta, max_eval=20) # tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_par = {'max_depth': 26.0, 'min_samples_split': 870.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_tree_learner2 = DecisionTreeRegressor(criterion='friedman_mse',\n",
    "                                              min_samples_split = int(best_par['min_samples_split']),\n",
    "                                              max_depth= int(best_par['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor( learning_rate=eta , n_estimators= 400 , Dist=Normal, Score=MLE,\n",
    "                       Base = default_tree_learner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=9.4403 val_loss=9.4329 scale=1.0000 norm=2408.2325\n",
      "[iter 100] loss=9.1305 val_loss=9.1681 scale=2.0000 norm=3643.3756\n",
      "[iter 200] loss=8.9702 val_loss=9.0773 scale=1.0000 norm=1619.2904\n",
      "[iter 300] loss=8.8825 val_loss=9.0499 scale=1.0000 norm=1538.7693\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL332 (val_loss=9.0471)\n"
     ]
    }
   ],
   "source": [
    "ngb = ngb_reg.fit(X = X_train, Y = Y_train, X_val = X_dev, Y_val = Y_dev, early_stopping_rounds=10)\n",
    "Y_preds = ngb.predict(X_dev)   \n",
    "Y_dists = ngb.pred_dist(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n"
     ]
    }
   ],
   "source": [
    "ntree = ngb.best_val_loss_itr\n",
    "print(ntree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = ngb.pred_param(X_dev)\n",
    "pars[:,1] = np.exp(pars[:,1])\n",
    "y_hat = pars[:,0]\n",
    "sig_hat = pars[:,1]\n",
    "\n",
    "WU2 = feather.read_dataframe('Data/WU.feather')\n",
    "all_test_MF = pd.DataFrame({\n",
    "    'Index': WU2[WU2.loc[:,'Set']=='dev'].loc[:,'Index'].values,\n",
    "    'Y': Y_dev,\n",
    "    'y_hat': y_hat,\n",
    "    'sig_hat': sig_hat,\n",
    "    'p_y': norm.pdf(Y_dev,loc=y_hat,scale=sig_hat)\n",
    "})\n",
    "\n",
    "path = 'Out_dev_MF\\\\month12\\\\NGB_dev_12m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb_reg = NGBRegressor( learning_rate=eta , n_estimators= ntree , Dist=Normal, Score=MLE,\n",
    "                       Base = default_tree_learner2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=9.4402 val_loss=0.0000 scale=1.0000 norm=2404.6652\n",
      "[iter 100] loss=9.1183 val_loss=0.0000 scale=1.0000 norm=1799.1731\n",
      "[iter 200] loss=8.9413 val_loss=0.0000 scale=1.0000 norm=1585.7410\n",
      "[iter 300] loss=8.8621 val_loss=0.0000 scale=1.0000 norm=1517.9531\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ngb_test = ngb_reg.fit(X = X_train_all, Y = Y_train_all)\n",
    "Y_preds = ngb_test.predict(X_test)   \n",
    "Y_dists = ngb_test.pred_dist(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & 2554.19 & 9.09 & 11316.43 & 7975.94 & 0.92 & 95\\% \\\\\n"
     ]
    }
   ],
   "source": [
    "pars = ngb_test.pred_param(X_test)\n",
    "zp95 = 1.959963984540\n",
    "y_hat = pars[:,0]\n",
    "sig_hat = np.exp(pars[:,1])\n",
    "left2 = (y_hat - sig_hat*zp95)\n",
    "right = (y_hat + sig_hat*zp95)\n",
    "\n",
    "\n",
    "r1,r2,r3,r4,r5 = get_RMSE_NLL_NOIS_AWPI_ECPI(Y_test,y_hat,left2,right,alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results\n",
    "with open(\"Results/Long_term_results.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"NGBoost \\n\")\n",
    "    myfile.write('RMSE %f & NLL %f & NOIS %f & AWPI %f & ECPI %f \\n' % (\n",
    "        r1,r2,r3,r4,r5 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WU2 = feather.read_dataframe('Data/WU.feather')\n",
    "WU2[WU2.loc[:,'Set']=='test'].loc[:,'Index'].values\n",
    "all_test_MF = pd.DataFrame({\n",
    "    'Index': WU2[WU2.loc[:,'Set']=='test'].loc[:,'Index'].values,\n",
    "    'Y': Y_test,\n",
    "    'y_hat': y_hat,\n",
    "    'sig_hat': sig_hat,\n",
    "    'p_y': norm.pdf(Y_test,loc=y_hat,scale=sig_hat)\n",
    "})\n",
    "\n",
    "path =  'Out_test_MF\\\\month12\\\\NGB_12m_dist.feather'\n",
    "feather.write_dataframe(all_test_MF , path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMA liklihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = ngb_test.pred_param(X_train_all)\n",
    "preds = pars[:,1]\n",
    "miu = pars[:,0]\n",
    "y =Y_train_all\n",
    "pi =  np.full(fill_value= np.pi, shape=np.shape(y)[0],dtype=float)\n",
    "nll = ( np.sum(0.5 *np.log(2*pi) + preds + 0.5 * ((y - miu)**2) * np.exp(-2*preds)))/y.shape[0]\n",
    "\n",
    "with open(\"Ensemble/BMA.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"NGBoost, %f \\n\" % (nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
